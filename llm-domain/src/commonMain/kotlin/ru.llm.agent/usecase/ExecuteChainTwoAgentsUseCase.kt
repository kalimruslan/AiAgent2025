package ru.llm.agent.usecase

import kotlinx.coroutines.flow.Flow
import kotlinx.coroutines.flow.flow
import kotlinx.serialization.json.Json
import ru.llm.agent.NetworkResult
import ru.llm.agent.RoleSender
import ru.llm.agent.model.AgentsChainResultModel
import ru.llm.agent.model.AssistantJsonAnswer
import ru.llm.agent.model.MessageModel
import ru.llm.agent.model.PromtFormat
import ru.llm.agent.model.Role
import ru.llm.agent.repository.LlmRepository

/**
 * UseCase –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ü–µ–ø–æ—á–∫–∏ –¥–≤—É—Ö –∞–≥–µ–Ω—Ç–æ–≤(–ø–µ—Ä–≤—ã–π –¥–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –∞ –≤—Ç–æ—Ä–æ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–µ–≥–æ –¥–µ–ª–∞–µ—Ç —á—Ç–æ-—Ç–æ)
 */
public class ExecuteChainTwoAgentsUseCase(
    private val llmRepository: LlmRepository
) {

    public suspend operator fun invoke(
        initialTask: MessageModel.UserMessage
    ): Flow<NetworkResult<AgentsChainResultModel>> = flow {
        var agentsChainResultModel = AgentsChainResultModel()
        llmRepository.sendMessageToProxyApi(
            roleSender = RoleSender.USER.type,
            text = initialTask.content,
            model = "gpt-4o-mini"
        ).collect {
            when (it) {
                is NetworkResult.Error -> emit(it as NetworkResult<AgentsChainResultModel>)
                is NetworkResult.Loading -> emit(it as NetworkResult<AgentsChainResultModel>)
                is NetworkResult.Success -> {
                    val parsed =
                        Json.decodeFromString<AssistantJsonAnswer>((it.data as MessageModel.ResponseMessage).content)

                    agentsChainResultModel = agentsChainResultModel.copy(
                        firstAgentMessage = parsed.answer.orEmpty()
                    )

                    val promtMessage = MessageModel.UserMessage(
                        role = Role.USER,
                        content = """
                    –¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö. –ü–æ–ª—É—á–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏—è ${initialTask.content} –æ—Ç –ø–µ—Ä–≤–æ–≥–æ –∞–≥–µ–Ω—Ç–∞:
                    ${parsed.answer.orEmpty()}

                    –¢–≤–æ—è –∑–∞–¥–∞—á–∞:
                            1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                            2. –°–æ–∑–¥–∞–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —ç—Ç–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                            3. –î–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

                            –û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
                            üìä –ê–ù–ê–õ–ò–ó:
                            [—Ç–≤–æ–π –∞–Ω–∞–ª–∏–∑]

                            üí° –ü–†–ê–ö–¢–ò–ß–ï–°–ö–ò–ô –ü–†–ò–ú–ï–†:
                            [–ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è]

                            ‚úÖ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:
                            [—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏]
                """.trimIndent()
                    )

                    llmRepository.sendMessageToYandexGPT(
                        promptMessage = null,
                        userMessage = promtMessage,
                        model = "gpt://b1gonedr4v7ke927m32n/yandexgpt-lite",
                        outputFormat = PromtFormat.TEXT
                    ).collect {
                        when (it) {
                            is NetworkResult.Error -> emit(it as NetworkResult<AgentsChainResultModel>)
                            is NetworkResult.Loading -> emit(
                                NetworkResult.Success(
                                    agentsChainResultModel
                                )
                            )

                            is NetworkResult.Success -> {
                                agentsChainResultModel = agentsChainResultModel.copy(
                                    secondAgentMessage = (it.data as MessageModel.ResponseMessage).content
                                )
                                emit(NetworkResult.Success(agentsChainResultModel))
                            }
                        }
                    }
                }
            }
        }
    }
}